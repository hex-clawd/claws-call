# Implementation Plan â€” Telegram Voice Call AI Assistant

## Current Status (v1.1.0)
âœ… Phase 1: Voice Message MVP â€” COMPLETE
âœ… Phase 2: Group Voice Chat Real-Time â€” COMPLETE (basic)
ðŸ”§ Phase 3: Polish â€” IN PROGRESS

## What Works
- Full pipeline: Audio â†’ VAD â†’ STT â†’ LLM â†’ TTS â†’ Playback
- Interruption handling (user can talk over bot)
- Clawdbot gateway integration
- [VOICE_CHAT] prefix for context awareness
- Markdown stripping before TTS

## Phases

### Phase 1: Voice Message MVP âœ…
- User sends voice msg â†’ bot transcribes â†’ Claude â†’ TTS â†’ voice msg reply
- Validate STT/LLM/TTS pipeline, format conversions, API integrations
- No real-time complexity yet
- Use Bot API (simple)

### Phase 2: Group Voice Chat Real-Time âœ…
- Userbot joins private group voice chat
- pytgcalls 2.x with RecordStream + ExternalMedia
- Silero VAD â†’ turn detection (700ms silence threshold)
- faster-whisper for STT
- Clawdbot gateway for LLM (routes to Hex)
- Edge TTS with ffmpeg decoding
- Async pipeline with interruption handling

### Phase 3: Polish ðŸ”§
- [x] Interruption handling
- [x] Markdown stripping
- [ ] **Streaming LLM â†’ TTS** (end goal for low latency)
- [x] Auto-join when user starts call (not bot-initiated)
- [x] Buffer drain before done (no more cut-off endings)
- [ ] Latency optimization (<2.5s target)
- [ ] Error recovery, reconnection logic

---

## Tech Stack

### Telegram
- **Userbot:** Pyrogram (cleaner API than Telethon)
- **Voice calls:** `pytgcalls[pyrogram]` v3.x with `GroupCallRaw`
- Session file for auth persistence

### STT
- **Option A (preferred):** `faster-whisper` + `whisper_streaming` (ufal)
  - Python-native, streaming-ready
  - Model: `base.en` or `small.en` (already have ggml at `~/clawd/models/ggml-small.en.bin`)
- **Option B:** whisper.cpp via subprocess
  - Lower overhead, but harder to integrate streaming

### VAD
- **Silero VAD** via `torch.hub.load('snakers4/silero-vad', 'silero_vad')`
- Threshold: 0.5 speech prob
- End-of-turn: 700ms silence

### LLM
- **Claude API** (Anthropic SDK)
- Streaming messages

### TTS
- **Edge TTS** streaming (primary)
- **Fallback:** Piper TTS (local, fast, free)
- Output: 16kHz PCM â†’ resample to 48kHz for Telegram

### Audio Processing
- `numpy`, `scipy` for resampling
- `pydub` or raw `struct` for format conversions
- `asyncio` for concurrent I/O

### Environment
- Python 3.11+ (M4-optimized)
- PyTorch with MPS backend for Silero VAD

---

## File Structure

```
telegram-voice-call/
â”œâ”€â”€ .env.example           # API keys template
â”œâ”€â”€ .env                   # API keys (gitignored)
â”œâ”€â”€ CLAUDE.md              # Project instructions
â”œâ”€â”€ RESEARCH.md            # Technical research
â”œâ”€â”€ PLAN.md                # This file
â”œâ”€â”€ requirements.txt       # Python deps
â”œâ”€â”€ main.py                # Entry point
â”œâ”€â”€ config.py              # Load env vars
â”œâ”€â”€ bot/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ userbot.py         # Pyrogram client setup
â”‚   â””â”€â”€ voice_chat.py      # pytgcalls GroupCallRaw integration
â”œâ”€â”€ audio/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ vad.py             # Silero VAD turn detection
â”‚   â”œâ”€â”€ stt.py             # Whisper STT (faster-whisper or whisper_streaming)
â”‚   â”œâ”€â”€ tts.py             # Edge TTS + Piper TTS
â”‚   â””â”€â”€ utils.py           # Resample, format conversion
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ claude.py          # Claude API streaming
â””â”€â”€ pipeline/
    â”œâ”€â”€ __init__.py
    â””â”€â”€ voice_pipeline.py  # Main async pipeline, interruption handling
```

---

## API Keys / Accounts Needed

### 1. Telegram Userbot
- **Phone number** (dedicated SIM recommended)
- **API credentials:** Get from https://my.telegram.org
  - `API_ID` (int)
  - `API_HASH` (str)
- **Session file:** Generated on first login via Pyrogram
  - Stored as `userbot.session` (gitignored)

### 2. Claude API
- **API key:** https://console.anthropic.com/
  - `ANTHROPIC_API_KEY`
- Model: `claude-3-5-sonnet-20241022` or latest

### 3. (Optional) Piper TTS
- No API key needed (local)
- Download model from https://github.com/rhasspy/piper/releases

---

## `.env.example`
```bash
# Telegram Userbot
API_ID=12345678
API_HASH=abcdef1234567890abcdef1234567890
PHONE_NUMBER=+1234567890

# Claude
ANTHROPIC_API_KEY=sk-ant-...

# Whisper
WHISPER_MODEL_PATH=~/clawd/models/ggml-small.en.bin

# Optional: Piper TTS fallback
PIPER_MODEL_PATH=~/models/piper/en_US-lessac-medium.onnx
```

---

## Implementation Details

### Audio Flow (Phase 2)
```python
# pseudocode
async def on_recorded_data(call, pcm_48k: bytes):
    # 1. Resample 48k â†’ 16k
    pcm_16k = resample(pcm_48k, 48000, 16000)

    # 2. VAD check
    is_speech = vad.check(pcm_16k)

    if is_speech and ai_is_speaking:
        # INTERRUPT: clear TTS buffer, stop playback
        interrupt()

    if is_speech:
        stt_buffer.append(pcm_16k)
    elif stt_buffer and silence_duration > 0.7:
        # Turn complete
        text = await stt.transcribe(stt_buffer)
        await handle_user_turn(text)

async def on_played_data(call, length: int) -> bytes:
    if tts_buffer:
        chunk = tts_buffer.popleft()
        # Resample 16k â†’ 48k if needed
        return resample(chunk, 16000, 48000)
    return b'\x00' * length  # silence

async def handle_user_turn(text: str):
    async for llm_chunk in claude.stream(text):
        async for audio_chunk in edge_tts.stream(llm_chunk):
            tts_buffer.append(audio_chunk)
```

### Key Async Patterns
- `asyncio.Queue` for audio buffers
- `asyncio.Event` for interruption signaling
- `asyncio.create_task` for concurrent TTS generation + playback

### Latency Optimizations
- Start TTS as soon as LLM produces first sentence
- Pre-buffer first 500ms of TTS before playing
- Use `faster-whisper` with `beam_size=1` (greedy decoding, faster)
- Use `ufal/whisper_streaming` for incremental transcription

---

## Unresolved Questions

1. **Whisper backend:** Use `faster-whisper` (Python) or whisper.cpp (subprocess)? Leaning toward `faster-whisper` for streaming integration.

2. **Private group setup:** Auto-create group on first run, or manual setup? Auto-create risks Telegram spam detection. Leaning toward manual with instructions.

3. **VAD parameters:** 700ms silence threshold OK, or need adaptive (longer silence for long answers)? Start with 700ms, tune later.

4. **TTS fallback:** Always use ElevenLabs, or detect API failure â†’ Piper fallback? Add fallback logic in Phase 3.

5. **Interruption UX:** Just stop TTS, or also cancel LLM generation? Cancel LLM to save costs + latency.

6. **Session persistence:** How to handle Pyrogram session file? Store as `userbot.session`, gitignore, document in README.

7. **Error recovery:** If voice chat disconnects, auto-rejoin? Yes, with exponential backoff.

8. **Multi-user:** Support multiple users in same group voice chat, or 1-on-1 only? Start with 1-on-1 (private group with 2 users).
